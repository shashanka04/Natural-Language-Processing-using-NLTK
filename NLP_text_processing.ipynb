{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement: NLP text processing**\n",
        "\n",
        "Write a Python program that reads the demotext.txttext file (provided on LMS). The  following  are  the  tasks  that  are  to  be  taken  into  consideration  while constructing the solution for text processing using the NLTK library.\n",
        "\n",
        "1.Load the demotext.txttext file into a variable and then close the file\n",
        "\n",
        "2.Do word-wise tokenization list out generated tokens\n",
        "\n",
        "3.Transform each token into a small case\n",
        "\n",
        "4.Remove stop words from the generated token list\n",
        "\n",
        "5.Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in anothervariable\n",
        "\n",
        "6.Do bigram and trigram for generated tokens"
      ],
      "metadata": {
        "id": "mcOkZRNRisHT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNfhCIqk35HH"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Load the demotext.txttext file into a variable and then close the file"
      ],
      "metadata": {
        "id": "GPZtr7PMi5_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x='''What is Lorem Ipsum?\n",
        "\n",
        "Lorem Ipsum is simply dummy text of the printing and\n",
        "typesetting industry. Lorem Ipsum has been the industry's\n",
        "standard dummy text ever since the 1500s, when an unknown\n",
        "printer took a galley of type and scrambled it to make a\n",
        "type specimen book. It has survived not only five centuries,\n",
        "but also the leap into electronic typesetting,\n",
        "remaining essentially unchanged.\n",
        "\n",
        "It was popularised in the 1960s with the release of Letraset\n",
        "sheets containing Lorem Ipsum passages, and more recently\n",
        "with desktop publishing software like Aldus PageMaker\n",
        "including versions of Lorem Ipsum.'''"
      ],
      "metadata": {
        "id": "KBCFO8i743g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "OEGd1u8k489T",
        "outputId": "a27b91ff-7b52-4d47-cb7e-669de950f311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is Lorem Ipsum?\\n\\nLorem Ipsum is simply dummy text of the printing and\\ntypesetting industry. Lorem Ipsum has been the industry's\\nstandard dummy text ever since the 1500s, when an unknown\\nprinter took a galley of type and scrambled it to make a\\ntype specimen book. It has survived not only five centuries,\\nbut also the leap into electronic typesetting,\\nremaining essentially unchanged.\\n\\nIt was popularised in the 1960s with the release of Letraset\\nsheets containing Lorem Ipsum passages, and more recently\\nwith desktop publishing software like Aldus PageMaker\\nincluding versions of Lorem Ipsum.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Do word-wise tokenization list out generated tokens"
      ],
      "metadata": {
        "id": "n4qHpffpi9jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNLDee2z6QqT",
        "outputId": "d0cb66e2-e915-46a5-c5d8-dcb617de647d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token=nltk.word_tokenize(x)\n",
        "display(token)"
      ],
      "metadata": {
        "id": "cwoo2nL_6d_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91df4315-a6ac-4ef2-8261-e5206ccecafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " '?',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'is',\n",
              " 'simply',\n",
              " 'dummy',\n",
              " 'text',\n",
              " 'of',\n",
              " 'the',\n",
              " 'printing',\n",
              " 'and',\n",
              " 'typesetting',\n",
              " 'industry',\n",
              " '.',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'has',\n",
              " 'been',\n",
              " 'the',\n",
              " \"industry's\",\n",
              " 'standard',\n",
              " 'dummy',\n",
              " 'text',\n",
              " 'ever',\n",
              " 'since',\n",
              " 'the',\n",
              " '1500s',\n",
              " ',',\n",
              " 'when',\n",
              " 'an',\n",
              " 'unknown',\n",
              " 'printer',\n",
              " 'took',\n",
              " 'a',\n",
              " 'galley',\n",
              " 'of',\n",
              " 'type',\n",
              " 'and',\n",
              " 'scrambled',\n",
              " 'it',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'type',\n",
              " 'specimen',\n",
              " 'book',\n",
              " '.',\n",
              " 'It',\n",
              " 'has',\n",
              " 'survived',\n",
              " 'not',\n",
              " 'only',\n",
              " 'five',\n",
              " 'centuries',\n",
              " ',',\n",
              " 'but',\n",
              " 'also',\n",
              " 'the',\n",
              " 'leap',\n",
              " 'into',\n",
              " 'electronic',\n",
              " 'typesetting',\n",
              " ',',\n",
              " 'remaining',\n",
              " 'essentially',\n",
              " 'unchanged',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'popularised',\n",
              " 'in',\n",
              " 'the',\n",
              " '1960s',\n",
              " 'with',\n",
              " 'the',\n",
              " 'release',\n",
              " 'of',\n",
              " 'Letraset',\n",
              " 'sheets',\n",
              " 'containing',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'passages',\n",
              " ',',\n",
              " 'and',\n",
              " 'more',\n",
              " 'recently',\n",
              " 'with',\n",
              " 'desktop',\n",
              " 'publishing',\n",
              " 'software',\n",
              " 'like',\n",
              " 'Aldus',\n",
              " 'PageMaker',\n",
              " 'including',\n",
              " 'versions',\n",
              " 'of',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " '.']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3.Transform each token into a small case"
      ],
      "metadata": {
        "id": "ZafTBGQKjBcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_case=set(i.lower() for i in token)\n",
        "lower_case"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntpECrKZ7cxy",
        "outputId": "4a5324b2-da1b-41d2-faab-b0623708742c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',',\n",
              " '.',\n",
              " '1500s',\n",
              " '1960s',\n",
              " '?',\n",
              " 'a',\n",
              " 'aldus',\n",
              " 'also',\n",
              " 'an',\n",
              " 'and',\n",
              " 'been',\n",
              " 'book',\n",
              " 'but',\n",
              " 'centuries',\n",
              " 'containing',\n",
              " 'desktop',\n",
              " 'dummy',\n",
              " 'electronic',\n",
              " 'essentially',\n",
              " 'ever',\n",
              " 'five',\n",
              " 'galley',\n",
              " 'has',\n",
              " 'in',\n",
              " 'including',\n",
              " 'industry',\n",
              " \"industry's\",\n",
              " 'into',\n",
              " 'ipsum',\n",
              " 'is',\n",
              " 'it',\n",
              " 'leap',\n",
              " 'letraset',\n",
              " 'like',\n",
              " 'lorem',\n",
              " 'make',\n",
              " 'more',\n",
              " 'not',\n",
              " 'of',\n",
              " 'only',\n",
              " 'pagemaker',\n",
              " 'passages',\n",
              " 'popularised',\n",
              " 'printer',\n",
              " 'printing',\n",
              " 'publishing',\n",
              " 'recently',\n",
              " 'release',\n",
              " 'remaining',\n",
              " 'scrambled',\n",
              " 'sheets',\n",
              " 'simply',\n",
              " 'since',\n",
              " 'software',\n",
              " 'specimen',\n",
              " 'standard',\n",
              " 'survived',\n",
              " 'text',\n",
              " 'the',\n",
              " 'to',\n",
              " 'took',\n",
              " 'type',\n",
              " 'typesetting',\n",
              " 'unchanged',\n",
              " 'unknown',\n",
              " 'versions',\n",
              " 'was',\n",
              " 'what',\n",
              " 'when',\n",
              " 'with'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Remove stop words from the generated token list"
      ],
      "metadata": {
        "id": "wIz3uqQ9jQcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxQOCIgA9fwN",
        "outputId": "7b195a99-bbf4-43c2-c89c-68101397de6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=set(stopwords.words('english'))\n",
        "s"
      ],
      "metadata": {
        "id": "KzTNbDhE9pAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list=[w for w in lower_case if w.lower()  not  in s ]\n",
        "print(\"stop words:\")\n",
        "word_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfjrA1VS_yjL",
        "outputId": "12ed3ecc-17e5-4f2f-a988-e16fef5a7a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stop words:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['desktop',\n",
              " 'dummy',\n",
              " 'centuries',\n",
              " 'unchanged',\n",
              " 'ipsum',\n",
              " 'also',\n",
              " 'lorem',\n",
              " 'popularised',\n",
              " 'letraset',\n",
              " 'software',\n",
              " '1960s',\n",
              " 'took',\n",
              " 'like',\n",
              " 'unknown',\n",
              " 'pagemaker',\n",
              " 'passages',\n",
              " 'type',\n",
              " 'versions',\n",
              " 'text',\n",
              " 'industry',\n",
              " 'book',\n",
              " 'electronic',\n",
              " \"industry's\",\n",
              " ',',\n",
              " '.',\n",
              " 'specimen',\n",
              " 'standard',\n",
              " 'since',\n",
              " 'galley',\n",
              " 'essentially',\n",
              " 'containing',\n",
              " 'survived',\n",
              " 'five',\n",
              " 'publishing',\n",
              " 'aldus',\n",
              " 'release',\n",
              " 'including',\n",
              " 'sheets',\n",
              " 'simply',\n",
              " 'ever',\n",
              " '1500s',\n",
              " 'leap',\n",
              " 'typesetting',\n",
              " 'scrambled',\n",
              " 'printer',\n",
              " 'recently',\n",
              " 'remaining',\n",
              " '?',\n",
              " 'make',\n",
              " 'printing']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Remove extra symbols like commas, full stops, and question marks using a regular expression tokenizer and store them in anothervariable"
      ],
      "metadata": {
        "id": "8vCYOmerjddb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "xgjQRXkCi7GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "iwQNb3GqjKzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(x)\n",
        "print(\"Filtered Tokens:\")\n",
        "display(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oP7yta2ojAJP",
        "outputId": "9597d631-760c-476e-950d-9a9ef8214910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'is',\n",
              " 'simply',\n",
              " 'dummy',\n",
              " 'text',\n",
              " 'of',\n",
              " 'the',\n",
              " 'printing',\n",
              " 'and',\n",
              " 'typesetting',\n",
              " 'industry',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'has',\n",
              " 'been',\n",
              " 'the',\n",
              " 'industry',\n",
              " 's',\n",
              " 'standard',\n",
              " 'dummy',\n",
              " 'text',\n",
              " 'ever',\n",
              " 'since',\n",
              " 'the',\n",
              " '1500s',\n",
              " 'when',\n",
              " 'an',\n",
              " 'unknown',\n",
              " 'printer',\n",
              " 'took',\n",
              " 'a',\n",
              " 'galley',\n",
              " 'of',\n",
              " 'type',\n",
              " 'and',\n",
              " 'scrambled',\n",
              " 'it',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'type',\n",
              " 'specimen',\n",
              " 'book',\n",
              " 'It',\n",
              " 'has',\n",
              " 'survived',\n",
              " 'not',\n",
              " 'only',\n",
              " 'five',\n",
              " 'centuries',\n",
              " 'but',\n",
              " 'also',\n",
              " 'the',\n",
              " 'leap',\n",
              " 'into',\n",
              " 'electronic',\n",
              " 'typesetting',\n",
              " 'remaining',\n",
              " 'essentially',\n",
              " 'unchanged',\n",
              " 'It',\n",
              " 'was',\n",
              " 'popularised',\n",
              " 'in',\n",
              " 'the',\n",
              " '1960s',\n",
              " 'with',\n",
              " 'the',\n",
              " 'release',\n",
              " 'of',\n",
              " 'Letraset',\n",
              " 'sheets',\n",
              " 'containing',\n",
              " 'Lorem',\n",
              " 'Ipsum',\n",
              " 'passages',\n",
              " 'and',\n",
              " 'more',\n",
              " 'recently',\n",
              " 'with',\n",
              " 'desktop',\n",
              " 'publishing',\n",
              " 'software',\n",
              " 'like',\n",
              " 'Aldus',\n",
              " 'PageMaker',\n",
              " 'including',\n",
              " 'versions',\n",
              " 'of',\n",
              " 'Lorem',\n",
              " 'Ipsum']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Do bigram and trigram for generated tokens"
      ],
      "metadata": {
        "id": "u4I9qQkijiN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = list(ngrams(word_list, 2))\n",
        "\n",
        "print(\"\\nBigrams:\")\n",
        "display(bigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "D2EzhwHzmAui",
        "outputId": "b242541a-a94e-4c51-988e-6ef1452d6a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigrams:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('desktop', 'dummy'),\n",
              " ('dummy', 'centuries'),\n",
              " ('centuries', 'unchanged'),\n",
              " ('unchanged', 'ipsum'),\n",
              " ('ipsum', 'also'),\n",
              " ('also', 'lorem'),\n",
              " ('lorem', 'popularised'),\n",
              " ('popularised', 'letraset'),\n",
              " ('letraset', 'software'),\n",
              " ('software', '1960s'),\n",
              " ('1960s', 'took'),\n",
              " ('took', 'like'),\n",
              " ('like', 'unknown'),\n",
              " ('unknown', 'pagemaker'),\n",
              " ('pagemaker', 'passages'),\n",
              " ('passages', 'type'),\n",
              " ('type', 'versions'),\n",
              " ('versions', 'text'),\n",
              " ('text', 'industry'),\n",
              " ('industry', 'book'),\n",
              " ('book', 'electronic'),\n",
              " ('electronic', \"industry's\"),\n",
              " (\"industry's\", ','),\n",
              " (',', '.'),\n",
              " ('.', 'specimen'),\n",
              " ('specimen', 'standard'),\n",
              " ('standard', 'since'),\n",
              " ('since', 'galley'),\n",
              " ('galley', 'essentially'),\n",
              " ('essentially', 'containing'),\n",
              " ('containing', 'survived'),\n",
              " ('survived', 'five'),\n",
              " ('five', 'publishing'),\n",
              " ('publishing', 'aldus'),\n",
              " ('aldus', 'release'),\n",
              " ('release', 'including'),\n",
              " ('including', 'sheets'),\n",
              " ('sheets', 'simply'),\n",
              " ('simply', 'ever'),\n",
              " ('ever', '1500s'),\n",
              " ('1500s', 'leap'),\n",
              " ('leap', 'typesetting'),\n",
              " ('typesetting', 'scrambled'),\n",
              " ('scrambled', 'printer'),\n",
              " ('printer', 'recently'),\n",
              " ('recently', 'remaining'),\n",
              " ('remaining', '?'),\n",
              " ('?', 'make'),\n",
              " ('make', 'printing')]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams = list(ngrams(word_list, 3))\n",
        "\n",
        "\n",
        "print(\"\\nTrigrams:\")\n",
        "display(trigrams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "inCiiTiomHRE",
        "outputId": "92d35d1e-54de-4a6a-d8f1-a008a258d422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('desktop', 'dummy', 'centuries'),\n",
              " ('dummy', 'centuries', 'unchanged'),\n",
              " ('centuries', 'unchanged', 'ipsum'),\n",
              " ('unchanged', 'ipsum', 'also'),\n",
              " ('ipsum', 'also', 'lorem'),\n",
              " ('also', 'lorem', 'popularised'),\n",
              " ('lorem', 'popularised', 'letraset'),\n",
              " ('popularised', 'letraset', 'software'),\n",
              " ('letraset', 'software', '1960s'),\n",
              " ('software', '1960s', 'took'),\n",
              " ('1960s', 'took', 'like'),\n",
              " ('took', 'like', 'unknown'),\n",
              " ('like', 'unknown', 'pagemaker'),\n",
              " ('unknown', 'pagemaker', 'passages'),\n",
              " ('pagemaker', 'passages', 'type'),\n",
              " ('passages', 'type', 'versions'),\n",
              " ('type', 'versions', 'text'),\n",
              " ('versions', 'text', 'industry'),\n",
              " ('text', 'industry', 'book'),\n",
              " ('industry', 'book', 'electronic'),\n",
              " ('book', 'electronic', \"industry's\"),\n",
              " ('electronic', \"industry's\", ','),\n",
              " (\"industry's\", ',', '.'),\n",
              " (',', '.', 'specimen'),\n",
              " ('.', 'specimen', 'standard'),\n",
              " ('specimen', 'standard', 'since'),\n",
              " ('standard', 'since', 'galley'),\n",
              " ('since', 'galley', 'essentially'),\n",
              " ('galley', 'essentially', 'containing'),\n",
              " ('essentially', 'containing', 'survived'),\n",
              " ('containing', 'survived', 'five'),\n",
              " ('survived', 'five', 'publishing'),\n",
              " ('five', 'publishing', 'aldus'),\n",
              " ('publishing', 'aldus', 'release'),\n",
              " ('aldus', 'release', 'including'),\n",
              " ('release', 'including', 'sheets'),\n",
              " ('including', 'sheets', 'simply'),\n",
              " ('sheets', 'simply', 'ever'),\n",
              " ('simply', 'ever', '1500s'),\n",
              " ('ever', '1500s', 'leap'),\n",
              " ('1500s', 'leap', 'typesetting'),\n",
              " ('leap', 'typesetting', 'scrambled'),\n",
              " ('typesetting', 'scrambled', 'printer'),\n",
              " ('scrambled', 'printer', 'recently'),\n",
              " ('printer', 'recently', 'remaining'),\n",
              " ('recently', 'remaining', '?'),\n",
              " ('remaining', '?', 'make'),\n",
              " ('?', 'make', 'printing')]"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}